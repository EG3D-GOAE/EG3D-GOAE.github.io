<!DOCTYPE html>

<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>EG3D-GOAE</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./files/bootstrap.min.css">
    <link rel="stylesheet" href="./files/font-awesome.min.css">
    <link rel="stylesheet" href="./files/codemirror.min.css">
    <link rel="stylesheet" href="./files/app.css">




</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-20 text-center">
                <br></br>
                Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent Portrait Synthesis from Monocular Image<br>
                <small>
                    Accepted by CVPR 2023
                </small>
            </h1>
            <hr style="margin-top:0px">
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="" style="font-size: 16px;">
                            Ziyang Yuan
                        </a>
                    </li>
                    <li>
                        <a href="https://kristen-rang.github.io/" style="font-size: 16px;">
                            Yiming Zhu
                        </a>
                    </li>
                    <li>
                        <a href="" style="font-size: 16px;">
                            Yu Li
                        </a>
                    </li>
                    <li>
                        <a href="" style="font-size: 16px;">
                            Hongyu Liu
                        </a>
                    </li>
                    <li>
                    <a></a><br>
                    <br>
                    <li>
                        <a href="https://www.tsinghua.edu.cn/en/" style="font-size: 16px;">
                            Tsinghua University
                        </a>
                    </li>



                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://arxiv.org">
                            <img src="./files/paper.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>

                    <li>
<!--                         <a onClick="alert('Code coming soon!\nContact dengyu2008@hotmail.com for more details.')"> -->
                        <a >
                            <img src="./files/github.png" height="60px">
                            <h4><strong>Code (coming soon)</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <a>
                    <video style="width:97%;height:97%;" playsinline autoplay loop preload muted>
                        <source src="./files/teaser.mp4" type="video/mp4">
                    </video>
                </a>
                <br></br>
                <h2>
                    Abstract
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    3D GAN inversion aims to achieve high reconstruction fidelity and reasonable 3D geometry simultaneously from a single image input.
                    However, existing 3D GAN inversion methods rely on time-consuming optimization for each individual case.  
                    In this work, we introduce a novel encoder-based inversion framework based on EG3D, one of the most widely-used 3D GAN models. 
                    We leverage the inherent properties of EG3D's latent space to design a discriminator and a background depth regularization.  
                    This enables us to train a geometry-aware encoder capable of converting the input image into corresponding latent code.  
                    Additionally, we explore the feature space of EG3D and develop an adaptive refinement stage that improves the representation ability of features in EG3D to enhance the recovery of fine-grained textural details.  
                    Finally, we propose an occlusion-aware fusion operation to prevent distortion in unobserved regions.  
                    Our method achieves impressive results comparable to optimization-based methods while operating up to 500 times faster. Our framework is well-suited for applications such as semantic editing.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Video
                </h2>
                <hr style="margin-top:0px">
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com" allowfullscreen=""
                            style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Pipeline
                </h2>
                <hr style="margin-top:0px">
                <img src="./files/framework.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify" style="font-size: 16px;">
                    Overview of our method. Our framework could be divided into two parts. (1) W space inversion. We design an encoder E to invert input image $I$ into w<sup>+</sup> latent codes. 
                    The w<sup>+</sup> latent codes are fed into a pre-trained EG3D generator $G$ to get $tri$-$planew<sub>(w<sup>+</sup>)</sub> and rendered into reconstruction image I<sub>(w<sup>+</sup>)</sub>. (2) Complement the F space. 
                    We calculate the image residual $\Delta I$ between the input image and its reconstruction and propose AFA module to refine the F latent maps. 
                    The modified latent maps $F^*$ are transformed into $tri$-$plane<sub>(mix)</sub> by occlusion-aware mix and rendered into the fine detailed inversion image $I<sub>(F<sup>*</sup>)</sub>.
                </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Novel View Synthesis
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                Novel view synthesis on CelebA-HQ. Our method can generate novel views of a portrait image with high-fidelity and 
                strong 3D-consistency via single forward pass.
                </p>
                <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                    <source src="./files/more_result.mp4" type="video/mp4">
                </video>
                <br></br>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Comparison with existing face editing methods. Our method faithfully reconstructs the given image and achieves better
                    3D-consistency under pose variations.
                    </p>
                    <video style="width:97%;height:97%;" playsinline autoplay loop preload muted>
                        <source src="./files/compare.mp4" type="video/mp4">
                    </video>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Dolly Zoom Effect
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Our method achieves dolly zoom effect of a portrait image by explicitly adjusting the camera position and fov, 
                    thanks to the underlying 3D representation.
                </p>
                <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                    <source src="./files/zoom.mp4" type="video/mp4">
                </video>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    3D-Consistent Editing
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    Our method can also be applied to 3D-consistent interactive portrait editing due to its ability
                    to preserve fine image details.
                </p>
                <video style="width:100%;height:100%;" playsinline autoplay loop preload muted>
                    <source src="./files/edit.mp4" type="video/mp4">
                </video>
            </div>
        </div>



        <div class="row">
            <div class="col-md-12 col-md-offset-0">
                <div class="text-center">
                    <h2>
                        Citation
                    </h2>
                </div>
                <hr style="margin-top:0px">
                <div class="form-group col-md-12 col-md-offset-0">
                    <div class="CodeMirror cm-s-default CodeMirror-wrap" style="font-size: 16px;">
                        <div
                            style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 4px; left: 4px; ">
                            <textarea autocorrect="off" autocapitalize="off" spellcheck="false"
                                style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"
                                tabindex="0"></textarea></div>
                        <div class="CodeMirror-vscrollbar" cm-not-content="true">
                            <div style="min-width: 1px; height: 0px;"></div>
                        </div>
                        <div class="CodeMirror-hscrollbar" cm-not-content="true">
                            <div style="height: 100%; min-height: 1px; width: 0px;"></div>
                        </div>
                        <div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div>
                        <div class="CodeMirror-gutter-filler" cm-not-content="true"></div>
                        <div class="CodeMirror-scroll" tabindex="-1">
                            <div class="CodeMirror-sizer"
                                style="margin-left: 0px; margin-bottom: -17px; border-right-width: 13px; min-height: 162px; padding-right: 0px; padding-bottom: 0px;">
                                <div style="position: relative; top: 0px;">
                                    <div class="CodeMirror-lines">
                                        <div style="position: relative; outline: none;">
                                            <div class="CodeMirror-measure">AخA</div>
                                            <div class="CodeMirror-measure"></div>
                                            <div style="position: relative; z-index: 1;"></div>
                                            <div class="CodeMirror-cursors">
                                                <div class="CodeMirror-cursor"
                                                    style="left: 4px; top: 0px; height: 17.1406px;">&nbsp;</div>
                                            </div>
                                            <div class="CodeMirror-code" style="">
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;">@article{deng2022learning,</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  title={Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent Portrait Synthesis from Monocular Image},</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  author={Deng, Yu and Wang, Baoyuan and Shum, Heung-Yeung},</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  journal={arXiv preprint arXiv:2211.13901},</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  year={2022}</span></pre>
                                                <pre
                                                    class=" CodeMirror-line "><span style="padding-right: 0.1px;">}</span></pre>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <div style="position: absolute; height: 13px; width: 1px; top: 280px;"></div>
                            <div class="CodeMirror-gutters" style="display: none; height: 300px;"></div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 col-md-offset-0 text-center">
                <br></br>
                <h2>
                    Acknowledgements
                </h2>
                <hr style="margin-top:0px">
                <p class="text-justify" style="font-size: 16px;">
                    We thank Xingyu Chen for the discussion to improve the paper. <br>
                    The website template was adapted from <a href="https://yudeng.github.io/GRAM/">GRAM</a>.
                </p>
            </div>
        </div>


</body>

</html>
